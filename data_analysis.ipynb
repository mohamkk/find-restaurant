{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 프로젝트 주제 : 맛집 탐방\n",
    "https://www.data.go.kr/data/15066516/fileData.do"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/content/gdrive/My Drive/모함ㅋ/용산구_맛집.csv\", encoding='cp949')  \n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import folium\n",
    "center = [37.541, 126.986]\n",
    "m = folium.Map(location=center, zoom_start=11, tiles=\"Stamenterrain\")\n",
    "\n",
    "m.add_child(folium.ClickForMarker()) # popup이 없으면 위도,경도 표시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# step1, step2 기능 구현\n",
    "from geopy.geocoders import Nominatim\n",
    "geo_local = Nominatim(user_agent='South Korea')\n",
    "# 위도, 경도 반환하는 함수\n",
    "def geocoding(address):\n",
    "    geo = geo_local.geocode(address)\n",
    "    x_y = [geo.latitude, geo.longitude]\n",
    "    return x_y\n",
    "\n",
    "    \n",
    "hyunho_address_name = input() #이태원동\n",
    "seoyoon_address_name = input() #우사단로4길\n",
    "\n",
    "# step 1\n",
    "hyunho_address = geocoding(hyunho_address_name) # [37.5270966, 127.0015525]\n",
    "seoyoon_address = geocoding(seoyoon_address_name) # [어쩌구,저쩌구]\n",
    "\n",
    "# step 2 : 중심 지점\n",
    "average_address = [(hyunho_address[0]+seoyoon_address[0])/2 , (hyunho_address[1]+seoyoon_address[1])/2]\n",
    "\n",
    "m = folium.Map(location = center, zoom_start=15)\n",
    "    \n",
    "#지도에 데이터 찍어서 보여주기\n",
    "folium.Marker(hyunho_address, tooltip=hyunho_address_name).add_to(m)\n",
    "folium.Marker(seoyoon_address, tooltip=seoyoon_address_name).add_to(m)\n",
    "folium.Marker(average_address, tooltip = '중심').add_to(m)\n",
    "\n",
    "# 거리 계산\n",
    "print(haversine(hyunho_address, seoyoon_address, unit = 'm'))\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ㅇ# step3 : 중심지에서 가까운(100m 이내) 맛집 위치 찾기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 중심지까지의 거리 구하기\n",
    "\n",
    "df2 = pd.DataFrame.copy(df)\n",
    "df2['중심지까지의 거리'] = None\n",
    "for i in range(len(df)):\n",
    "  lat = df.iloc[i,7]\n",
    "  lon = df.iloc[i,8]\n",
    "  dis = haversine([lat, lon], average_address, unit='m')\n",
    "  df2.iloc[i,10] = dis\n",
    "\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2[df2['중심지까지의 거리'] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location = average_address, zoom_start=16)\n",
    "df_100 = df2[df2['중심지까지의 거리'] < 100]\n",
    "for i in df_100.index:\n",
    "    sub_lat =  df_100.loc[i,'위도']\n",
    "    sub_long = df_100.loc[i,'경도']\n",
    "    \n",
    "    title = df_100.loc[i,'업소명']\n",
    "    menu = df_100.loc[i, '주요요리']\n",
    "    \n",
    "    #지도에 데이터 찍어서 보여주기\n",
    "    folium.Marker([sub_lat,sub_long],tooltip = title, popup = menu).add_to(map)\n",
    "    # folium.Marker([sub_lat,sub_long], popup = menu).add_to(map)\n",
    "\n",
    "folium.Marker(hyunho_address,tooltip = hyunho_address_name, icon=folium.Icon(icon = \"info-sign\",color = \"red\")).add_to(map)\n",
    "folium.Marker(seoyoon_address,tooltip = seoyoon_address_name, icon=folium.Icon(icon = \"info-sign\",color = \"red\")).add_to(map)\n",
    "folium.Marker(average_address,tooltip = '중심',icon=folium.Icon(icon = \"cloud\",color = \"green\")).add_to(map)\n",
    "# folium.Marker(hyunho_address,icon=folium.Icon(icon = \"info-sign\",color = \"red\")).add_to(map)\n",
    "# folium.Marker(seoyoon_address,icon=folium.Icon(icon = \"info-sign\",color = \"red\")).add_to(map)\n",
    "# folium.Marker(average_address,icon=folium.Icon(icon = \"cloud\",color = \"green\")).add_to(map)\n",
    "\n",
    "# Circle = 미터단위 /  CircleMarker = 픽셀단위(확대, 축소를 해도 원의 크기가 비율에 맞춰 일정하게유지)\n",
    "folium.Circle(location=average_address, radius=100, color=\"blue\", fill=True).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step4. 먹기 싫은 음식 걸러내기\n",
    "- 먹기 싫은 음식의 키워드가 들어간 메뉴를 파는 가게는 보여주지 않는다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = pd.DataFrame.copy(df2)\n",
    "# for menu in ['소고기','비프','규','한우']:\n",
    "#   df_cow = df3[df3['주요요리'].str.contains(menu)]\n",
    "#   print(df_cow.주요요리)\n",
    "\n",
    "# for menu in ['소고기','비프','규','한우']:\n",
    "#   df_cow = df3[df3['주요요리'].str.contains(menu)]\n",
    "#   df_not_cow = df3.drop(df_cow)\n",
    "#   # print(df_cow.주요요리)\n",
    "# print(df_not_cow)\n",
    "def to_nan(x):\n",
    "  for menu in ['소고기','비프','규','한우']:\n",
    "    if menu in x:\n",
    "      return np.NaN\n",
    "  \n",
    "  return x\n",
    "    \n",
    "\n",
    "df_not_cow = pd.DataFrame.copy(df3)\n",
    "df_not_cow['주요요리'] = df_not_cow['주요요리'].apply(lambda x: to_nan(x))\n",
    "df_not_cow_2 = df_not_cow[df_not_cow['주요요리'].notna()]  # notna : True, False 값으로 나옴"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_not_cow_2[df_not_cow_2['중심지까지의 거리'] < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "map = folium.Map(location = average_address, zoom_start=16)\n",
    "df_not_cow_100 = df_not_cow_2[df_not_cow_2['중심지까지의 거리'] < 100]\n",
    "for i in df_not_cow_100.index:\n",
    "    sub_lat =  df_not_cow_100.loc[i,'위도']\n",
    "    sub_long = df_not_cow_100.loc[i,'경도']\n",
    "    \n",
    "    title = df_not_cow_100.loc[i,'업소명']\n",
    "    menu = df_not_cow_100.loc[i, '주요요리']\n",
    "    \n",
    "    #지도에 데이터 찍어서 보여주기\n",
    "    folium.Marker([sub_lat,sub_long],tooltip = title, popup = menu).add_to(map)\n",
    "    # folium.Marker([sub_lat,sub_long], popup = menu).add_to(map)\n",
    "\n",
    "folium.Marker(hyunho_address,tooltip = hyunho_address_name, icon=folium.Icon(icon = \"info-sign\",color = \"red\")).add_to(map)\n",
    "folium.Marker(seoyoon_address,tooltip = seoyoon_address_name, icon=folium.Icon(icon = \"info-sign\",color = \"red\")).add_to(map)\n",
    "folium.Marker(average_address,tooltip = '중심',icon=folium.Icon(icon = \"cloud\",color = \"green\")).add_to(map)\n",
    "# folium.Marker(hyunho_address,icon=folium.Icon(icon = \"info-sign\",color = \"red\")).add_to(map)\n",
    "# folium.Marker(seoyoon_address,icon=folium.Icon(icon = \"info-sign\",color = \"red\")).add_to(map)\n",
    "# folium.Marker(average_address,icon=folium.Icon(icon = \"cloud\",color = \"green\")).add_to(map)\n",
    "\n",
    "# Circle = 미터단위 /  CircleMarker = 픽셀단위(확대, 축소를 해도 원의 크기가 비율에 맞춰 일정하게유지)\n",
    "folium.Circle(location=average_address, radius=100, color=\"blue\", fill=True).add_to(map)\n",
    "\n",
    "map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step5 : 크롤링 - Selenium\n",
    "### 문제점 \n",
    "- 네이버 플레이스에 없는 음식점이 많다\n",
    "- 가게마다 메뉴 표시가 다르다\n",
    "- 동명의 가게가 많다\n",
    "### 해결방안\n",
    "- 망고플레이트(https://www.mangoplate.com/)에서 크롤링 진행\n",
    "- 각종 맛집에 대한 정보와 음식 사진을 가져올 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install selenium\n",
    "!apt-get update\n",
    "!apt install chromium-chromedriver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote_plus\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome('chromedriver', chrome_options=chrome_options)\n",
    "\n",
    "\n",
    "url = \"https://www.mangoplate.com/restaurants/z7EYi8LIox\"\n",
    "driver.get(url)\n",
    "element = driver.find_element_by_xpath(\"/html/body/main/article/div[1]/div[1]/div/section[3]/ul/li[1]/a/div[2]/ul/li[1]/button/img\")\n",
    "\n",
    "img_url = element.get_attribute(\"data-src\")\n",
    "img_url = img_url.split('?')[0]\n",
    "print(img_url)\n",
    "driver.close()\n",
    "\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# time check\n",
    "start = time.time()\n",
    "\n",
    "# curl 요청\n",
    "# curl \"이미지 주소\" > \"저장 될 이미지 파일 이름\" \n",
    "os.system(\"curl \" + img_url + \" > test1.jpg\")\n",
    "\n",
    "# 이미지 다운로드 시간 체크\n",
    "print(time.time() - start)\n",
    "\n",
    "\n",
    "# 저장 된 이미지 확인\n",
    "curl_img = Image.open(\"/content/test1.jpg\")\n",
    "curl_img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Step 6. 딥러닝으로 음식사진 데이터 Classification\n",
    "### 출처 : kaggle https://www.kaggle.com/rkuo2000/food11-classification/data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_dir = \"/content/gdrive/MyDrive/모함ㅋ/training\"\n",
    "val_dir   = \"/content/gdrive/MyDrive/모함ㅋ/validation\"\n",
    "test_dir  = \"/content/gdrive/MyDrive/모함ㅋ/evaluation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "target_size = (224,224) # 임의로 줘도 된다. 단 딥러닝 들어갈때 shape를 맞춰주기만 하면 된다\n",
    "# 보편적으로 224x224로 이미지 학습\n",
    "batch_size = 16 # batch = epoch를 한번에 넣으면 학습시간이 오래걸려서 나눠서 넣는다.\n",
    "# 이미지 16개씩 학습할 것이다. -> 정확도는 좀 떨어지지만 학습속도 향상\n",
    "\n",
    "# Data Generator\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1./255, # RGB(0,0,0) 픽셀값 정규화\n",
    "#    rotation_range=40, # 데이터 증식(증강) 과정 : 주석 풀면서 더 향상된 학습 하기 위해 \n",
    "#    width_shift_range=0.2,\n",
    "#    height_shift_range=0.2,\n",
    "#    shear_range=0.2,\n",
    "#    zoom_range=0.2,\n",
    "   horizontal_flip=True,\n",
    "   vertical_flip=True\n",
    ")\n",
    "\n",
    "# path의 데이터를 ImageDataGenerator로 불러와주는 우리만의 함수를 만들자!\n",
    "# def get_dataset(path, datagen, shuffle):\n",
    "#     data_set = datagen.flow_from_directory(path,\n",
    "#                                            target_size=target_size,\n",
    "#                                            batch_size=batch_size, # 한 번에 이미지 두 장씩\n",
    "#                                            class_mode='categorical', # cats, dogs 두 개면 binary를 쓰기도 함.\n",
    "#                                            color_mode='rgb',\n",
    "#                                            shuffle=shuffle, # True or False\n",
    "#                                            seed=42)   # data shuffle시에 쓰는 난수값(얼마나 shuffle할 것이냐?)                  \n",
    "\n",
    "#     return data_set\n",
    "\n",
    "# train_generator = get_dataset(train_dir, train_datagen, True)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',    \n",
    "    shuffle=True,\n",
    "    seed=42,\n",
    "    class_mode='categorical') # 각 사진에 대한 train_y label 을 매칭시켜줄 필요는 없을\n",
    "    # 것으로 보임. ImageDataGenerator가 알아서 분류를 해줌([['Bread'], ['Bread'].,..]) 이런 식\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    val_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    shuffle=False,    \n",
    "    class_mode='categorical')\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "target_size = (224,224) # 임의로 줘도 된다. 단 딥러닝 들어갈때 shape를 맞춰주기만 하면 된다\n",
    "# 보편적으로 224x224로 이미지 학습\n",
    "batch_size = 16\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=target_size,\n",
    "    batch_size=batch_size,\n",
    "    color_mode='rgb',\n",
    "    shuffle=False,    \n",
    "    class_mode='categorical')\n",
    "\n",
    "print(test_generator) #class_indices 한번 보기\n",
    "print(list(test_generator.class_indices))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = list(test_generator.class_indices.keys())\n",
    "# print(labels)\n",
    "print(test_generator.class_indices)\n",
    "print(test_generator.classes)\n",
    "# 궁금증 해결!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "EfficientNet Transfer learning \n",
    "참고 사이트 : https://www.kaggle.com/rkuo2000/food11-classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q efficientnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import efficientnet.tfkeras as efn # 미리 학습된 efficient net을 가져와서 transfer learning 할 것\n",
    "\n",
    "base_model = efn.EfficientNetB7(input_shape=(224,224,3), weights='imagenet', include_top=False)\n",
    "# 이 모델은 (224, 224, 3) shape의 이미지를 취하며 입력 데이터의 범위는 [0, 255]여야합니다. Normalization은 모델에 포함되어 있습니다.\n",
    "# ImageNet에서 EfficientNet을 교육하려면 모델 아키텍처 자체의 일부가 아닌 엄청난 양의 리소스와 \n",
    "# 여러 기술이 필요하기 때문에 Keras에서 EfficientNet 구현은 기본적으로 AutoAugment을 통한 \n",
    "# training을 바탕으로 얻어진 pretrained weights 로드를 통해 이뤄집니다.\n",
    "\n",
    "# include_top은 기존의 top_layer(output layer)를 제외하고\n",
    "# 우리가 레이어 조금 더 수정하고 싶을 때 False로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build Model\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import GlobalAveragePooling2D, Dense\n",
    "# Conv2D로 2차원 할건데 왜 Flatten 으로 1차원으로 펴주냐?\n",
    "# Classfier 를 쓰기 위해서는 FC를 써야 하고, 그러려면 1차원 벡터를 써야한다 그래서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = len(labels) # food-11가지 아까 위에서 정의함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ver1. kaggle 전이학습 그대로 하는 코드\n",
    "# Add Extra Layers to Model\n",
    "x=base_model.output # 전체 모델 다 가져옴\n",
    "x=GlobalAveragePooling2D()(x) # 여기부터는 우리가 추가하는 custom layers들\n",
    "x=Dense(512,activation='relu')(x) \n",
    "x=Dense(64,activation='relu')(x) \n",
    "out=Dense(num_classes,activation='softmax')(x) #final layer with softmax activation\n",
    "\n",
    "model=Model(inputs=base_model.input,outputs=out)\n",
    "#          (  맨 첫 layer     , out= out을 만들기 위해 필요한 모든 layer들  )\n",
    "# base_model.input은 inputlayer만 말하고, base_model.output은 전체 모델을 다 가져오는\n",
    "# 것으로 이해했다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Transfer Learning\n",
    "base_model.trainable = False #기껏 imagenet에서 가져온 weight를 또 수정하진 않을 것"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary() # BatchNormalization 이란 activation가기 전에 픽셀값들을 정규화해서 데이터 스케일을 맞춰주는 작업이다~라고 간단히 이해함\n",
    "# 출처 : Batch Normalization 설명 https://light-tree.tistory.com/139"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile Model\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model\n",
    "num_epochs = 20\n",
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST =test_generator.n//test_generator.batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "\n",
    "cb_earlystop = tf.keras.callbacks.EarlyStopping( monitor = 'val_loss' , \n",
    "                                                 mode = 'auto',\n",
    "                                                 verbose = 1,\n",
    "                                                 patience = 2 )\n",
    "                                                 # patience : 2번 이상 성능이 개선되지 않으면 멈춘다\n",
    "                                                 \n",
    "# ModelCheckpoint 콜백함수의 인스턴스를 cb_chkpnt 저장합니다.\n",
    "cb_chkpnt = tf.keras.callbacks.ModelCheckpoint( filepath = \"./chkpnt/{epoch:04d}.ckpt\", \n",
    "                                             monitor = 'val_loss',\n",
    "                                             mode = 'auto',  \n",
    "                                             verbose = 1, \n",
    "                                             save_best_only = False,\n",
    "                                             save_weights_only = False,\n",
    "                                             save_freq = 'epoch' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit / train_generator (X_train, y_train) 같은 것\n",
    "model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, epochs=num_epochs, \n",
    "          validation_data=valid_generator, validation_steps=STEP_SIZE_VALID, callbacks=[cb_earlystop, cb_chkpnt])\n",
    "# model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, epochs=1, \n",
    "#           validation_data=valid_generator, validation_steps=STEP_SIZE_VALID)\n",
    "model.save(\"saved_model_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 불러와서 이어서 학습하기\n",
    "\n",
    "loaded_model = tf.keras.models.load_model(\"saved_model_1\")\n",
    "# with tf.device(\"/device:GPU:0\"):\n",
    "loaded_model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, epochs=20, initial_epoch = 10,\n",
    "        validation_data=valid_generator, validation_steps=STEP_SIZE_VALID)\n",
    "loaded_model.save(\"saved_model_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "import tensorflow as tf\n",
    "loaded_model = tf.keras.models.load_model(\"/content/gdrive/My Drive/모함ㅋ/0202_saved_model_hyunho\")\n",
    "\n",
    "STEP_SIZE_TEST =test_generator.n//test_generator.batch_size\n",
    "loss, acc = loaded_model.evaluate(test_generator, steps=STEP_SIZE_TEST)\n",
    "print(\"The accuracy of the model is {:.3f}\\nThe Loss in the model is {:.3f}\".format(acc,loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion Matrix(=혼동행렬) : 행에 예측된 클래스의 인스턴스, 열에 실제 클래스의 인스턴스를 나타내는 성능 지표이다.\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "preds=model.predict(test_generator)\n",
    "y_pred = np.argmax(preds,axis=1)\n",
    "y_actual = test_generator.classes\n",
    "cm = confusion_matrix(y_actual, y_pred)\n",
    "print(cm)\n",
    "print(classification_report(y_actual, y_pred, target_names=labels))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "망고플레이트 이미지 predict 시작!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# colab 크롤링 버전(driver install만 하면 사용 가능) 이 위에 !pip install 먼저 하고 오셈 -> 로컬에서는 따로 설치 과정이 필요\n",
    "\n",
    "from selenium import webdriver\n",
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup as bs\n",
    "from urllib.parse import quote_plus\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "\n",
    "chrome_options = webdriver.ChromeOptions()\n",
    "chrome_options.add_argument('--headless')\n",
    "chrome_options.add_argument('--no-sandbox')\n",
    "chrome_options.add_argument('--disable-dev-shm-usage')\n",
    "driver = webdriver.Chrome('chromedriver', chrome_options=chrome_options)\n",
    "\n",
    "\n",
    "url = \"https://www.mangoplate.com/restaurants/z7EYi8LIox\"\n",
    "driver.get(url)\n",
    "element = driver.find_element_by_xpath(\"/html/body/main/article/div[1]/div[1]/div/section[3]/ul/li[1]/a/div[2]/ul/li[1]/button/img\")\n",
    "\n",
    "img_url = element.get_attribute(\"data-src\")\n",
    "img_url = img_url.split('?')[0]\n",
    "print(img_url)\n",
    "driver.close()\n",
    "\n",
    "import os\n",
    "import time\n",
    "from PIL import Image\n",
    "\n",
    "# time check\n",
    "start = time.time()\n",
    "\n",
    "# curl 요청\n",
    "# curl \"이미지 주소\" > \"저장 될 이미지 파일 이름\" \n",
    "os.system(\"curl \" + img_url + \" > test1.jpg\")\n",
    "\n",
    "# 이미지 다운로드 시간 체크\n",
    "print(time.time() - start)\n",
    "\n",
    "\n",
    "# 저장 된 이미지 확인\n",
    "curl_img = Image.open(\"/content/test1.jpg\")\n",
    "curl_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# predict 코드\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
    "\n",
    "img = load_img('./testImg/test2.jpg', target_size = (224, 224))\n",
    "img = img_to_array(img)\n",
    "print(img.shape)\n",
    "img = np.expand_dims(img, axis=0)\n",
    "print(img.shape)\n",
    "img = np.vstack([img])\n",
    "print(img.shape)\n",
    "classes = loaded_model.predict(img, batch_size=10) # -> batch_size????\n",
    "\n",
    "print(classes)\n",
    "print(np.argmax(classes))\n",
    "# np.argmax(classes, axis = 1) -> axis가 무엇인지 알아오기\n",
    "print(labels[np.argmax(classes)])"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "74d2343ad4dff75b49c0a429738c89574287364f8aa457c8c162112606763eec"
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
